[Running nsys_wrap.sh rank: 1]
output----bert_prof/bert-large_chimera_4stages_4gpus_microbs128_acc1_node_rank1
python: /usr/bin/python3.8 /usr/lib/python3.8 /usr/lib/python3.9 /usr/lib/python2.7 /etc/python3.8 /usr/local/lib/python3.8 /opt/conda/bin/python3.8 /opt/conda/bin/python /opt/conda/bin/python3.8-config
/workspace/Chimera
Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.
当前时间: 2024-06-09 22:45:07
tcp://192.168.0.5:1234
1
local_rank 1, local_size 2, rank-1, world_size-4
[[stage_to_ranks]] -> {0: [0, 3], 1: [1, 2], 2: [2, 1], 3: [3, 0]}
[[[[[[[[[[9999]]]]]]]]]]
[[[[[[[[[[9999]]]]]]]]]]
[total_num_samples_per_step: 512]]]]]]]]]]
[max_steps_per_epoch:        19]]]]]]]]]]
total_num_samples: 4096 num_epochs: 1
[[pytorch sync]] 0 epoch
[[Chimera start]] 0 epoch
[<pipeline.PipelineStage object at 0x7ff74d8da760>, <pipeline.PipelineStage object at 0x7ff74d8da9a0>]
shiiitttt epoch-0 step-0 num_steps_for_this_epoch-8 num_p2p_comm-16
/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:909: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Exception in thread Thread-5:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.8/threading.py", line 870, in run
    self.run()
  File "/opt/conda/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/Chimera/pipeline.py", line 160, in recv_comm_thread
    self._target(*self._args, **self._kwargs)
  File "/workspace/Chimera/pipeline.py", line 160, in recv_comm_thread
    dist.recv(tensor=recv_tensor, src=src_rank, tag=tag)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 977, in recv
    dist.recv(tensor=recv_tensor, src=src_rank, tag=tag)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 977, in recv
    pg.recv([tensor], src, tag).wait()
RuntimeError: [/opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.5]:6326
    pg.recv([tensor], src, tag).wait()
RuntimeError: [/opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.5]:6326

The target application terminated with signal 9 (SIGKILL)

The application terminated before the collection started. No report was generated.
Training script completed at Sun Jun  9 22:46:24 +03 2024
scp: /workspace/Chimera/bert_prof/bert-large_chimera_4stages_4gpus_microbs128_acc1_rank3.qdrep: No such file or directory
scp: /workspace/Chimera/bert_prof/bert-large_chimera_4stages_4gpus_microbs128_acc1_rank3.sqlite: No such file or directory
scp: /workspace/Chimera/bert_prof/bert-large_chimera_4stages_4gpus_microbs32_acc1_rank2.qdrep: No such file or directory
scp: /workspace/Chimera/bert_prof/bert-large_chimera_4stages_4gpus_microbs32_acc1_rank2.sqlite: No such file or directory
scp: /workspace/Chimera/bert_prof/bert-large_chimera_4stages_4gpus_microbs32_acc1_rank3.qdrep: No such file or directory
scp: /workspace/Chimera/bert_prof/bert-large_chimera_4stages_4gpus_microbs32_acc1_rank3.sqlite: No such file or directory
nsys script completed at Sun Jun  9 22:47:22 +03 2024
